df$agnWard=as.factor(res.agnesWard$cluster) #the as.factor function converts vectors into categorical variables
df$agnAvgDist=as.factor(res.agnesAvgDist$cluster)
df$dia=as.factor(res.diana$cluster)
#Verifying ordinality: Below I use the GNIusd variable to assess the ordering that the clusters represent on this indicator:
aggregate(data=df,
GNIusd~agnWard,
FUN=mean)
#Verifying ordinality: Below I use the GNIusd variable to assess the ordering that the clusters represent on this indicator:
aggregate(data=df,
GNIusd~dia,
FUN=mean)
#To evaluate the robustness of results, I start by computing the "silhouette measure" for each observation under each of the approaches to clustering:
fviz_silhouette(res.agnesWard)
#To evaluate the robustness of results, I start by computing the "silhouette measure" for each observation under each of the approaches used for clustering:
fviz_silhouette(res.agnesAvgDist)
#To evaluate the robustness of results, I start by computing the "silhouette measure" for each observation under each of the approaches to clustering:
fviz_silhouette(res.diana)
#Saving silhouette measures for each observation under all methods:
agnWardEval=data.frame(res.agnesWard$silinfo$widths)
agnAvgDistEval=data.frame(res.agnesAvgDist$silinfo$widths)
diaEval=data.frame(res.diana$silinfo$widths)
#Creating an object with silhouette measures that have negative values (i.e., indicating wrongly clustered cases):
agnWardPoor=rownames(agnWardEval[agnWardEval$sil_width<0,])
agnAvgDistPoor=rownames(agnAvgDistEval[agnAvgDistEval$sil_width<0,])
diaPoor=rownames(diaEval[diaEval$sil_width<0,])
library("qpcR")
#Creating a dataframe based on the above vectors, sorted in ascending order and bound with missing values using the cbind.na function to maintain the same number of rows:
bad_Clus=as.data.frame(qpcR:::cbind.na(sort(agnWardPoor),
sort(agnAvgDistPoor),
sort(diaPoor)))
#Assigning a name for the columns in the bad_Clus dataframe:
names(bad_Clus)=c("agnWard", "agnAvgDist", "dia")
bad_Clus
#Checking the cases of wrong clustering:
bad_Clus
#Generating visual representations to illustrate the output for the two methods:
#Agnes Ward Linkage Criteria:
#Labeling the wrongly clustered cases:
library(ggrepel) #package needed to avoid text label overlaps
LABELagn=ifelse(df$Country%in%agnWardPoor,df$Country,"")
base = ggplot(data=df,
aes(x=V1, y=V2,
label=Country))
agnWardPlot=base + labs(title = "AGNES Ward Link") + geom_point(size=2,
aes(color=agnWard),
show.legend = T)
#Adding labels:
agnWardPlot2 = agnWardPlot +
geom_text_repel(aes(label=LABELagn),
max.overlaps = 50,
min.segment.length = unit(0, 'lines'))
agnWardPlot2
#Agnes Average Distance Linkage Criteria:
base = ggplot(data=df,
aes(x=V1, y=V2,
label=Country))
agnAvgDistPlot=base + labs(title = "AGNES Avg Dist Link") + geom_point(size=2,
aes(color=agnAvgDist),
show.legend = T)
#Labeling the wrongly clustered cases:
LABELagn2=ifelse(df$Country%in%agnAvgDistPoor,df$Country,"")
#Adding labels:
agnAvgDistPlot2 = agnAvgDistPlot +
geom_text_repel(aes(label=LABELagn2),
max.overlaps = 50,
min.segment.length = unit(0, 'lines'))
agnAvgDistPlot2
#Generating the same plot for the Diana method:
diaPlot=base + labs(title = "DIANA") + geom_point(size=2,
aes(color=dia),
show.legend = T)
diaPlot
#Juxtaposing the plots using the ggpubr package:
library(ggpubr)
ggarrange(agnWardPlot2, agnAvgDistPlot2, diaPlot,ncol = 3,common.legend = T)
#Generating a dendogram for the Agnes approach:
fviz_dend(res.agnesWard,
k=NumberOfClusterDesired,
cex = 0.45,
horiz = T,
main = "AGNES approach",
scale = "none")
#Generating a dendogram for the Diana approach:
fviz_dend(res.diana,
k=NumberOfClusterDesired,
cex = 0.45,
horiz = T,
main = "DIANA approach",
scale = "none")
library(tidyverse)
library(cluster)
library(factoextra)
#Generating four clusters using the non-hierarchical k-means clustering approach:
set.seed(999)
k = kmeans(dataToCluster, centers = 4)
k
fviz_cluster(k, data = dataToCluster)
#Removing row names to better identify potential overlaps between clusters:
fviz_cluster(k, data = dataToCluster,
geom = "point",
ggtheme = theme_minimal(),
repel = TRUE)
#Generating four clusters using the non-hierarchical k-means clustering approach:
set.seed(123)
k = kmeans(dataToCluster, centers = 4)
k
fviz_cluster(k, data = dataToCluster)
#Generating four clusters using the non-hierarchical k-means clustering approach:
set.seed(980)
k = kmeans(dataToCluster, centers = 4)
k
fviz_cluster(k, data = dataToCluster)
#Generating four clusters using the non-hierarchical k-means clustering approach:
k = kmeans(dataToCluster, centers = 4)
k
fviz_cluster(k, data = dataToCluster)
#Generating four clusters using the non-hierarchical k-means clustering approach:
k = kmeans(dataToCluster, centers = 4)
k
fviz_cluster(k, data = dataToCluster)
#Generating four clusters using the non-hierarchical k-means clustering approach:
set.seed(999)
k = kmeans(dataToCluster, centers = 4)
k
fviz_cluster(k, data = dataToCluster)
#Generating four clusters using the non-hierarchical k-means clustering approach:
set.seed(617)
k = kmeans(dataToCluster, centers = 4)
k
fviz_cluster(k, data = dataToCluster)
#Generating four clusters using the non-hierarchical k-means clustering approach:
set.seed(458)
k = kmeans(dataToCluster, centers = 4)
k
fviz_cluster(k, data = dataToCluster)
#Cleaning the memory:
rm(list = ls())
#Providing the link to the R-dataframe location in the Github repository:
link='https://github.com/elenapopic542/Deliverable-2/raw/main/wbdata.RDS'
#Reading-in the R-dataframe using the readRDS function:
df=readRDS(file = url(link))
#Reset indexes to address concerns that index will start at "0" (given that the data were exported from a Pandas dataframe):
row.names(df)=NULL
#Verifying the data types:
str(df)
#Creating a new dataframe with the subset of columns assigned for clustering purposes:
dataToCluster=df[,c(6,7,8,9,10)]
#Saving the country names as the row names:
row.names(dataToCluster)=df$Country
#Setting the seed for result-replication purposes:
set.seed(999)
library(cluster)
#Using the default Euclidian method for the computation of distances, given that all variables are numeric:
distanceMatrix=daisy(x=dataToCluster)
#Creating an object to store the coordinates for two-dimensional mapping:
mappingData = cmdscale(distanceMatrix, k=2)
#From the previously created mapping.Data object, saving coordinates to the original dataframe:
df$V1 = mappingData[,1]
df$V2 = mappingData[,2]
#Checking the first ten rows:
df[,c('V1','V2')][1:10,]
# Creating a plot to illustrate the points represented by the above coordinates to check for potentially emerging groups of countries:
library(ggplot2)
base = ggplot(data=df,
aes(x=V1, y=V2,
label=Country))
base + geom_text(size=1)
# Hierarchical clustering:
hrclust = hclust(distanceMatrix)
# As an alternative to the above map, creating a dendogram to check for potentially emerging groups of countries:
plot(hrclust,hang = -1,cex=0.5)
library(factoextra)
#Identifying the suggested optimal number of clusters using the agglomerative approach to hierarchical clustering:
fviz_nbclust(dataToCluster,
hcut, #hierarchical clustering object
diss=distanceMatrix,
method = "gap_stat", #gap statistic is the method
k.max = 10,
verbose = F,
hc_func = "agnes", #agnes is the function for the agglomerative approach to clustering
ggtheme = theme_minimal() + theme(text = element_text(size = 16)),
linecolor = "salmon")
#Identifying the suggested optimal number of clusters using the divisive technique to hierarchical clustering:
fviz_nbclust(dataToCluster,
hcut,
diss=distanceMatrix,
method = "gap_stat", #gap statistic is the method
k.max = 10,
verbose = F,
hc_func = "diana", #diana is the function for the divisive approach to clustering
ggtheme = theme_minimal() + theme(text = element_text(size = 16)),
linecolor = "salmon")
#Identifying the suggested optimal number of clusters using the agglomerative technique to hierarchical clustering and the average silhouette method:
fviz_nbclust(dataToCluster,
hcut,
diss=distanceMatrix,
method = "silhouette", #average silhouette is the method
k.max = 10,
verbose = F,
hc_func = "agnes",
ggtheme = theme_minimal() + theme(text = element_text(size = 16)),
linecolor = "salmon")
#Setting the suggested number of two clusters:
NumberOfClusterDesired=2
#Aggregative approach:
res.agnesWard = hcut(distanceMatrix,
k = NumberOfClusterDesired,
isdiss=TRUE,
hc_func='agnes',
hc_method = "ward.D2") #using Ward's linkage criteria
res.agnesAvgDist = hcut(distanceMatrix,
k = NumberOfClusterDesired,
isdiss=TRUE,
hc_func='agnes',
hc_method = "average") #using the average distance linkage criteria
#Divisive approach:
res.diana = hcut(distanceMatrix,
k = NumberOfClusterDesired,
isdiss=TRUE,
hc_func='diana',
hc_method = "ward.D2") #using Ward's linkage criteria
#Saving the clustering results stored in the res.agnes object to the original dataframe:
df$agnWard=as.factor(res.agnesWard$cluster) #the as.factor function converts vectors into categorical variables
df$agnAvgDist=as.factor(res.agnesAvgDist$cluster)
df$dia=as.factor(res.diana$cluster)
#Verifying ordinality: Below I use the GNIusd variable to assess the ordering that the clusters represent on this indicator:
aggregate(data=df,
GNIusd~agnWard,
FUN=mean)
#Verifying ordinality: Below I use the GNIusd variable to assess the ordering that the clusters represent on this indicator:
aggregate(data=df,
GNIusd~dia,
FUN=mean)
#To evaluate the robustness of results, I start by computing the "silhouette measure" for each observation under each of the approaches to clustering:
fviz_silhouette(res.agnesWard)
#To evaluate the robustness of results, I start by computing the "silhouette measure" for each observation under each of the approaches used for clustering:
fviz_silhouette(res.agnesAvgDist)
#To evaluate the robustness of results, I start by computing the "silhouette measure" for each observation under each of the approaches to clustering:
fviz_silhouette(res.diana)
#Saving silhouette measures for each observation under all methods:
agnWardEval=data.frame(res.agnesWard$silinfo$widths)
agnAvgDistEval=data.frame(res.agnesAvgDist$silinfo$widths)
diaEval=data.frame(res.diana$silinfo$widths)
#Creating an object with silhouette measures that have negative values (i.e., indicating wrongly clustered cases):
agnWardPoor=rownames(agnWardEval[agnWardEval$sil_width<0,])
agnAvgDistPoor=rownames(agnAvgDistEval[agnAvgDistEval$sil_width<0,])
diaPoor=rownames(diaEval[diaEval$sil_width<0,])
library("qpcR")
#Creating a dataframe based on the above vectors, sorted in ascending order and bound with missing values using the cbind.na function to maintain the same number of rows:
bad_Clus=as.data.frame(qpcR:::cbind.na(sort(agnWardPoor),
sort(agnAvgDistPoor),
sort(diaPoor)))
#Assigning a name for the columns in the bad_Clus dataframe:
names(bad_Clus)=c("agnWard", "agnAvgDist", "dia")
bad_Clus
#Checking the cases of wrong clustering:
bad_Clus
#Generating visual representations to illustrate the output for the two methods:
#Agnes Ward Linkage Criteria:
#Labeling the wrongly clustered cases:
library(ggrepel) #package needed to avoid text label overlaps
LABELagn=ifelse(df$Country%in%agnWardPoor,df$Country,"")
base = ggplot(data=df,
aes(x=V1, y=V2,
label=Country))
agnWardPlot=base + labs(title = "AGNES Ward Link") + geom_point(size=2,
aes(color=agnWard),
show.legend = T)
#Adding labels:
agnWardPlot2 = agnWardPlot +
geom_text_repel(aes(label=LABELagn),
max.overlaps = 50,
min.segment.length = unit(0, 'lines'))
agnWardPlot2
#Agnes Average Distance Linkage Criteria:
base = ggplot(data=df,
aes(x=V1, y=V2,
label=Country))
agnAvgDistPlot=base + labs(title = "AGNES Avg Dist Link") + geom_point(size=2,
aes(color=agnAvgDist),
show.legend = T)
#Labeling the wrongly clustered cases:
LABELagn2=ifelse(df$Country%in%agnAvgDistPoor,df$Country,"")
#Adding labels:
agnAvgDistPlot2 = agnAvgDistPlot +
geom_text_repel(aes(label=LABELagn2),
max.overlaps = 50,
min.segment.length = unit(0, 'lines'))
agnAvgDistPlot2
#Generating the same plot for the Diana method:
diaPlot=base + labs(title = "DIANA") + geom_point(size=2,
aes(color=dia),
show.legend = T)
diaPlot
#Juxtaposing the plots using the ggpubr package:
library(ggpubr)
ggarrange(agnWardPlot2, agnAvgDistPlot2, diaPlot,ncol = 3,common.legend = T)
#Generating a dendogram for the Agnes approach:
fviz_dend(res.agnesWard,
k=NumberOfClusterDesired,
cex = 0.45,
horiz = T,
main = "AGNES approach",
scale = "none")
#Generating a dendogram for the Diana approach:
fviz_dend(res.diana,
k=NumberOfClusterDesired,
cex = 0.45,
horiz = T,
main = "DIANA approach",
scale = "none")
library(tidyverse)
library(cluster)
library(factoextra)
#Generating four clusters using the non-hierarchical k-means clustering approach:
k = kmeans(dataToCluster, centers = 4)
k
fviz_cluster(k, data = dataToCluster)
#Removing row names to better identify potential overlaps between clusters:
fviz_cluster(k, data = dataToCluster,
geom = "point",
ggtheme = theme_minimal(),
repel = TRUE)
#Cleaning the memory:
rm(list = ls())
#Providing the link to the R-dataframe location in the Github repository:
link='https://github.com/elenapopic542/Deliverable-2/raw/main/wbdata.RDS'
#Reading-in the R-dataframe using the readRDS function:
df=readRDS(file = url(link))
#Reset indexes to address concerns that index will start at "0" (given that the data were exported from a Pandas dataframe):
row.names(df)=NULL
#Verifying the data types:
str(df)
#Creating a new dataframe with the subset of columns assigned for clustering purposes:
dataToCluster=df[,c(6,7,8,9,10)]
#Saving the country names as the row names:
row.names(dataToCluster)=df$Country
#Setting the seed for result-replication purposes:
#set.seed(999)
library(cluster)
#Using the default Euclidian method for the computation of distances, given that all variables are numeric:
distanceMatrix=daisy(x=dataToCluster)
#Creating an object to store the coordinates for two-dimensional mapping:
mappingData = cmdscale(distanceMatrix, k=2)
#From the previously created mapping.Data object, saving coordinates to the original dataframe:
df$V1 = mappingData[,1]
df$V2 = mappingData[,2]
#Checking the first ten rows:
df[,c('V1','V2')][1:10,]
# Creating a plot to illustrate the points represented by the above coordinates to check for potentially emerging groups of countries:
library(ggplot2)
base = ggplot(data=df,
aes(x=V1, y=V2,
label=Country))
base + geom_text(size=1)
# Hierarchical clustering:
hrclust = hclust(distanceMatrix)
# As an alternative to the above map, creating a dendogram to check for potentially emerging groups of countries:
plot(hrclust,hang = -1,cex=0.5)
library(factoextra)
#Identifying the suggested optimal number of clusters using the agglomerative approach to hierarchical clustering:
fviz_nbclust(dataToCluster,
hcut, #hierarchical clustering object
diss=distanceMatrix,
method = "gap_stat", #gap statistic is the method
k.max = 10,
verbose = F,
hc_func = "agnes", #agnes is the function for the agglomerative approach to clustering
ggtheme = theme_minimal() + theme(text = element_text(size = 16)),
linecolor = "salmon")
#Identifying the suggested optimal number of clusters using the divisive technique to hierarchical clustering:
fviz_nbclust(dataToCluster,
hcut,
diss=distanceMatrix,
method = "gap_stat", #gap statistic is the method
k.max = 10,
verbose = F,
hc_func = "diana", #diana is the function for the divisive approach to clustering
ggtheme = theme_minimal() + theme(text = element_text(size = 16)),
linecolor = "salmon")
#Identifying the suggested optimal number of clusters using the agglomerative technique to hierarchical clustering and the average silhouette method:
fviz_nbclust(dataToCluster,
hcut,
diss=distanceMatrix,
method = "silhouette", #average silhouette is the method
k.max = 10,
verbose = F,
hc_func = "agnes",
ggtheme = theme_minimal() + theme(text = element_text(size = 16)),
linecolor = "salmon")
#Setting the suggested number of two clusters:
NumberOfClusterDesired=2
#Aggregative approach:
res.agnesWard = hcut(distanceMatrix,
k = NumberOfClusterDesired,
isdiss=TRUE,
hc_func='agnes',
hc_method = "ward.D2") #using Ward's linkage criteria
res.agnesAvgDist = hcut(distanceMatrix,
k = NumberOfClusterDesired,
isdiss=TRUE,
hc_func='agnes',
hc_method = "average") #using the average distance linkage criteria
#Divisive approach:
res.diana = hcut(distanceMatrix,
k = NumberOfClusterDesired,
isdiss=TRUE,
hc_func='diana',
hc_method = "ward.D2") #using Ward's linkage criteria
#Saving the clustering results stored in the res.agnes object to the original dataframe:
df$agnWard=as.factor(res.agnesWard$cluster) #the as.factor function converts vectors into categorical variables
df$agnAvgDist=as.factor(res.agnesAvgDist$cluster)
df$dia=as.factor(res.diana$cluster)
#Verifying ordinality: Below I use the GNIusd variable to assess the ordering that the clusters represent on this indicator:
aggregate(data=df,
GNIusd~agnWard,
FUN=mean)
#Verifying ordinality: Below I use the GNIusd variable to assess the ordering that the clusters represent on this indicator:
aggregate(data=df,
GNIusd~dia,
FUN=mean)
#To evaluate the robustness of results, I start by computing the "silhouette measure" for each observation under each of the approaches to clustering:
fviz_silhouette(res.agnesWard)
#To evaluate the robustness of results, I start by computing the "silhouette measure" for each observation under each of the approaches used for clustering:
fviz_silhouette(res.agnesAvgDist)
#To evaluate the robustness of results, I start by computing the "silhouette measure" for each observation under each of the approaches to clustering:
fviz_silhouette(res.diana)
#Saving silhouette measures for each observation under all methods:
agnWardEval=data.frame(res.agnesWard$silinfo$widths)
agnAvgDistEval=data.frame(res.agnesAvgDist$silinfo$widths)
diaEval=data.frame(res.diana$silinfo$widths)
#Creating an object with silhouette measures that have negative values (i.e., indicating wrongly clustered cases):
agnWardPoor=rownames(agnWardEval[agnWardEval$sil_width<0,])
agnAvgDistPoor=rownames(agnAvgDistEval[agnAvgDistEval$sil_width<0,])
diaPoor=rownames(diaEval[diaEval$sil_width<0,])
library("qpcR")
#Creating a dataframe based on the above vectors, sorted in ascending order and bound with missing values using the cbind.na function to maintain the same number of rows:
bad_Clus=as.data.frame(qpcR:::cbind.na(sort(agnWardPoor),
sort(agnAvgDistPoor),
sort(diaPoor)))
#Assigning a name for the columns in the bad_Clus dataframe:
names(bad_Clus)=c("agnWard", "agnAvgDist", "dia")
bad_Clus
#Checking the cases of wrong clustering:
bad_Clus
#Generating visual representations to illustrate the output for the two methods:
#Agnes Ward Linkage Criteria:
#Labeling the wrongly clustered cases:
library(ggrepel) #package needed to avoid text label overlaps
LABELagn=ifelse(df$Country%in%agnWardPoor,df$Country,"")
base = ggplot(data=df,
aes(x=V1, y=V2,
label=Country))
agnWardPlot=base + labs(title = "AGNES Ward Link") + geom_point(size=2,
aes(color=agnWard),
show.legend = T)
#Adding labels:
agnWardPlot2 = agnWardPlot +
geom_text_repel(aes(label=LABELagn),
max.overlaps = 50,
min.segment.length = unit(0, 'lines'))
agnWardPlot2
#Agnes Average Distance Linkage Criteria:
base = ggplot(data=df,
aes(x=V1, y=V2,
label=Country))
agnAvgDistPlot=base + labs(title = "AGNES Avg Dist Link") + geom_point(size=2,
aes(color=agnAvgDist),
show.legend = T)
#Labeling the wrongly clustered cases:
LABELagn2=ifelse(df$Country%in%agnAvgDistPoor,df$Country,"")
#Adding labels:
agnAvgDistPlot2 = agnAvgDistPlot +
geom_text_repel(aes(label=LABELagn2),
max.overlaps = 50,
min.segment.length = unit(0, 'lines'))
agnAvgDistPlot2
#Generating the same plot for the Diana method:
diaPlot=base + labs(title = "DIANA") + geom_point(size=2,
aes(color=dia),
show.legend = T)
diaPlot
#Juxtaposing the plots using the ggpubr package:
library(ggpubr)
ggarrange(agnWardPlot2, agnAvgDistPlot2, diaPlot,ncol = 3,common.legend = T)
#Generating a dendogram for the Agnes approach:
fviz_dend(res.agnesWard,
k=NumberOfClusterDesired,
cex = 0.45,
horiz = T,
main = "AGNES approach",
scale = "none")
#Generating a dendogram for the Diana approach:
fviz_dend(res.diana,
k=NumberOfClusterDesired,
cex = 0.45,
horiz = T,
main = "DIANA approach",
scale = "none")
library(tidyverse)
library(cluster)
library(factoextra)
#Generating four clusters using the non-hierarchical k-means clustering approach:
k = kmeans(dataToCluster, centers = 4)
k
fviz_cluster(k, data = dataToCluster)
#Removing row names to better identify potential overlaps between clusters:
fviz_cluster(k, data = dataToCluster,
geom = "point",
ggtheme = theme_minimal(),
repel = TRUE)
unlink("Deliverable2 copy_cache", recursive = TRUE)
